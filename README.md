ğŸ©º Medical Chatbot using Local LLM (Flask + LangChain)

A medical questionâ€“answering chatbot built using Flask, LangChain, and a local Large Language Model (LLM).
The chatbot provides token-by-token streaming responses, supports dark mode, and has a modern chat UI similar to ChatGPT.

âš ï¸ This chatbot is for educational and informational purposes only and does not replace professional medical advice.

ğŸš€ Features

ğŸ§  Local LLM (No OpenAI API required)

ğŸ” Retrieval-Augmented Generation (RAG) using FAISS

ğŸ’¬ Token-by-token streaming UI (live typing effect)

ğŸŒ™ Dark Mode toggle

ğŸ¨ Clean ChatGPT-style UI

ğŸ—‚ï¸ Medical document embeddings (HuggingFace)

ğŸ§‘â€âš•ï¸ Medical-focused responses

âš¡ Lightweight & beginner-friendly

ğŸ› ï¸ Tech Stack

Frontend  -> HTML, CSS, JavaScript

Backend	-> Flask

Mongo-DB  ->   for storing Chat between user and Bot

LLM Framework	-> LangChain

Embeddings	-> HuggingFace

Vector DB	-> FAISS

Local Model	-> TinyLLaMA / LLaMA (GGUF)

Styling	    -> Custom CSS (Light + Dark mode)


ğŸ’¬ How It Works

User enters a medical query

Query is embedded using HuggingFace embeddings

Relevant medical documents retrieved via FAISS

Prompt sent to local LLM

Response streamed token-by-token to UI

ğŸŒ™ Dark Mode

Click Dark Mode in the sidebar to toggle between:

â˜€ï¸ Light Mode

ğŸŒ™ Dark Mode

âš ï¸ Medical Disclaimer

This chatbot is not a doctor.
It provides general medical information only.
Always consult a qualified healthcare professional for diagnosis and treatment.


ğŸ”® Future Improvements

âœ… True backend streaming (WebSockets)

ğŸ§  Conversation memory

ğŸ“„ PDF upload support

ğŸ“± Mobile responsiveness

â˜ï¸ Cloud deployment

ğŸ§ª Model fine-tuning



ğŸ‘¤ Author

Mohmmad Anish
M.SC. AI & ML | GenAI Project
